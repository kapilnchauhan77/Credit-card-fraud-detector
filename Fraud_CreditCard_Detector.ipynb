{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Fraud_CreditCard_Detector.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapilnchauhan77/Credit-card-fraud-detector/blob/master/Fraud_CreditCard_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e90ixCwreYui",
        "colab_type": "code",
        "outputId": "28c6c689-5261-45ca-9d30-841517d7e736",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pugehpSMdurG",
        "colab_type": "text"
      },
      "source": [
        ">> # Importing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEHgWMERdurH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import scipy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siqy_fp4dz3r",
        "colab_type": "text"
      },
      "source": [
        "## Importing file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SGEXmKTd6l1",
        "colab_type": "code",
        "outputId": "b7027f78-9d28-4981-ec0f-29ba821255cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"kapilnchauhan77\" \n",
        "os.environ['KAGGLE_KEY'] = \"c3b03cc006b17dc2bf01e0038240aaf8\" \n",
        "!kaggle competitions download -c ieee-fraud-detection "
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZwun5ESeWrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "zf = ZipFile('train_transaction.csv.zip', 'r')\n",
        "zf.extractall()\n",
        "zf.close()\n",
        "\n",
        "zf = ZipFile('train_identity.csv.zip', 'r')\n",
        "zf.extractall()\n",
        "zf.close()\n",
        "\n",
        "zf = ZipFile('test_transaction.csv.zip', 'r')\n",
        "zf.extractall()\n",
        "zf.close()\n",
        "\n",
        "zf = ZipFile('test_identity.csv.zip', 'r')\n",
        "zf.extractall()\n",
        "zf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYRSVBxsdurL",
        "colab_type": "text"
      },
      "source": [
        ">> # Data Processing For Virtualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lOi-9yhdurM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ttc = pd.read_csv('train_transaction.csv', low_memory=False)\n",
        "tic = pd.read_csv('train_identity.csv', low_memory=False)\n",
        "tstc = pd.read_csv('test_transaction.csv', low_memory=False)\n",
        "tstic = pd.read_csv('test_identity.csv', low_memory=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo51YDwMdurO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    numv = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2 \n",
        "    for col in df.columns:\n",
        "        vt = df[col].dtypes\n",
        "        if vt in numv:\n",
        "            max_c = df[col].max()\n",
        "            min_c = df[col].min()\n",
        "            if str(vt)[:3] == 'int':\n",
        "                if min_c > np.iinfo(np.int8).min and max_c < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif min_c > np.iinfo(np.int16).min and max_c < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif min_c > np.iinfo(np.int32).min and max_c < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif min_c > np.iinfo(np.int64).min and max_c < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if min_c > np.finfo(np.float16).min and max_c < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif min_c > np.finfo(np.float32).min and max_c < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                elif min_c > np.finfo(np.float64).min and max_c < np.finfo(np.float64).max:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be-EV9hVdurQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ttc = reduce_mem_usage(ttc)\n",
        "tic = reduce_mem_usage(tic)\n",
        "tstc = reduce_mem_usage(tstc)\n",
        "tstic = reduce_mem_usage(tstic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEIirNtcdurT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.merge(ttc, tic, on = 'TransactionID', how = 'left')\n",
        "test = pd.merge(tstc, tstic, on = 'TransactionID', how = 'left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyLkvGXrdurV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del ttc, tic, tstc, tstic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPkbo_FTdurX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "miss_data = pd.isnull(train).sum().sort_values(ascending=False)\n",
        "miss_per = (miss_data/len(train))*100\n",
        "missing_data = pd.concat(objs = [miss_data, miss_per], keys = ['Columns','Missing values percentage'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubA7E3lAdurZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def delnullcol(dt):\n",
        "    nullcol = [col for col in dt.columns if dt[col].isnull().sum()/dt.shape[0] >= 0.9]\n",
        "    return nullcol"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCfvQHgOdurb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rep_vals = [col for col in train.columns if train[col].value_counts(dropna = False, normalize = True).values[0] >= 0.9]\n",
        "cols=[]\n",
        "for col in rep_vals:\n",
        "    cols.append(train[col].value_counts(dropna = False).values[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1GWBpKPdure",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def repcols(dt):\n",
        "    rep_vals = [col for col in dt.columns if dt[col].value_counts(dropna = False, normalize = True).values[0] >= 0.9]\n",
        "    return rep_vals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bin3sWKZdurh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def useless_cols(dt, exep):\n",
        "    null_cols = delnullcol(dt)\n",
        "    print(\"More than 90% null: \" + str(len(null_cols)))\n",
        "    too_many_repeated = repcols(dt)\n",
        "    print(\"More than 90% repeated value: \" + str(len(too_many_repeated)))\n",
        "    cols_to_drop = list(set(null_cols + too_many_repeated))\n",
        "    cols_to_drop.remove(exep)\n",
        "    return cols_to_drop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BtQHUtSdurj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols_to_drop = useless_cols(train, 'isFraud')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkwT-wlndurl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_Major_values(dt, threshold):\n",
        "    Major_values = []\n",
        "    t=dt.value_counts(dropna = True, normalize = True)\n",
        "    for i in range(len(t)):\n",
        "        if t.values[i] >= threshold:\n",
        "            Major_values.append(t.values[i])\n",
        "    return Major_values       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-aY3T36durn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_Major_Devices(Major_values,dt):\n",
        "    Major_Devices = []\n",
        "    t = dt.value_counts(dropna = True, normalize = True)\n",
        "    for i in Major_values:\n",
        "        for j in t.items():\n",
        "            if j[1] == i:\n",
        "                Major_Devices.append(j[0])\n",
        "    return Major_Devices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEhiYOxpduro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_plot(Major_Devices,d,dt):\n",
        "    plothis=[]\n",
        "    for i in range(len(Major_Devices)):\n",
        "        plothis.append(d.loc[dt == Major_Devices[i]])\n",
        "    if len(plothis) == 0:\n",
        "        return 10\n",
        "    else:\n",
        "        plothis = pd.concat(objs = [i for i in plothis], axis = 0)\n",
        "        return plothis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diV4AtbGdurq",
        "colab_type": "text"
      },
      "source": [
        ">> ## Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9oea4DWdurr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(style = \"whitegrid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kscwl1Cdurt",
        "colab_type": "text"
      },
      "source": [
        "## Plot for missing values in the columns in the training dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB3uuiFzdurt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(100,25))\n",
        "p = sns.barplot(x = 'Columns', y = 'Missing values percentage', data = missing_data)\n",
        "p.set_xticklabels(list(train.columns))\n",
        "p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcY7ZZzIdurv",
        "colab_type": "text"
      },
      "source": [
        "## For showing the columns with  over 90% repitetive data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKJifW3vdurw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(100,25))\n",
        "p2 = sns.barplot(x = rep_vals, y = cols)\n",
        "plt.title(\"Columns with most repetetive data\")\n",
        "p2.set(xlabel='Columns', ylabel='Number of replitions')\n",
        "p2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "23saehWydury",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Kpy_L1sdur1",
        "colab_type": "text"
      },
      "source": [
        "## Amount V Fraud "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "nNbhF1uydur2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amnt = sns.barplot(x = train['isFraud'], y = train['TransactionAmt'], data = train)\n",
        "plt.title(\"Amount V Fraud\")\n",
        "amnt.set_xticklabels(['Not Fraud','Fraud'])\n",
        "amnt.set(xlabel='Transaction Amount')\n",
        "amnt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XatU471hdur4",
        "colab_type": "text"
      },
      "source": [
        "## ProductCD V Fraud count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58lawo6Ndur5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot(train['ProductCD'], hue='isFraud', data=train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1im6pKKdur7",
        "colab_type": "text"
      },
      "source": [
        "## Major types of used Cards V  Number of frauds and not frauds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB4MqxZVdur7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1,7):\n",
        "    mv1 = find_Major_values(train['card'+str(i)], 0.05)\n",
        "    md1 = find_Major_Devices(mv1, train['card'+str(i)])\n",
        "    plothis1 = find_plot(md1, train, train['card'+str(i)])\n",
        "    plt.figure(figsize=(12,5))\n",
        "    if type(plothis1) != int:\n",
        "        p4 = sns.countplot(x = plothis1['card'+str(i)], hue = plothis1['isFraud'], data= plothis1)\n",
        "        plt.title(\"Data analysis of card number \"+str(i))\n",
        "        p4.set(xlabel='card data of card number '+str(i), ylabel='Count')\n",
        "        p4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiOJu9iMdur9",
        "colab_type": "text"
      },
      "source": [
        "## Major used C cases V count of fraud "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niXuo5Iydur-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1, 15):\n",
        "    mv1 = find_Major_values(train['C' + str(i)], 0.05)\n",
        "    md1 = find_Major_Devices(mv1, train['C' + str(i)])\n",
        "    plothis1 = find_plot(md1, train, train['C' + str(i)])\n",
        "    plt.figure(figsize=(12,5))\n",
        "    if type(plothis1) != int:\n",
        "        p4 = sns.countplot(x = plothis1['C' + str(i)], hue = plothis1['isFraud'], data= plothis1)\n",
        "        plt.title(\"Data analysis of C\" + str(i))\n",
        "        p4.set(xlabel='C data of C' + str(i), ylabel='Count')\n",
        "        p4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koXachbwdusA",
        "colab_type": "text"
      },
      "source": [
        "## Major used D cases V count of fraud "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYbIsgujdusA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1, 16):\n",
        "    mv1 = find_Major_values(train['D' + str(i)], 0.05)\n",
        "    md1 = find_Major_Devices(mv1, train['D' + str(i)])\n",
        "    plothis1 = find_plot(md1, train, train['D' + str(i)])\n",
        "    plt.figure(figsize=(12,5))\n",
        "    if type(plothis1) != int:\n",
        "        p4 = sns.countplot(x = plothis1['D' + str(i)], hue = plothis1['isFraud'], data= plothis1)\n",
        "        plt.title(\"Data analysis of D\" + str(i))\n",
        "        p4.set(xlabel='D data of D' + str(i), ylabel='Count')\n",
        "        p4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuu-H8FSdusC",
        "colab_type": "text"
      },
      "source": [
        "## Major used M cases V count of fraud "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOMIYQz6dusD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1, 10):\n",
        "    mv1 = find_Major_values(train['M' + str(i)], 0.05)\n",
        "    md1 = find_Major_Devices(mv1, train['M' + str(i)])\n",
        "    plothis1 = find_plot(md1, train, train['M' + str(i)])\n",
        "    plt.figure(figsize=(12,5))\n",
        "    if type(plothis1) != int:\n",
        "        p4 = sns.countplot(x = plothis1['M' + str(i)], hue = plothis1['isFraud'], data= plothis1)\n",
        "        plt.title(\"Data analysis of M\" + str(i))\n",
        "        p4.set(xlabel='M data of M' + str(i), ylabel='Count')\n",
        "        p4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IRSK1uxdusE",
        "colab_type": "text"
      },
      "source": [
        "## Most used IDs V fraud count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "i5jrqvo7dusF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1,10):\n",
        "    mv1 = find_Major_values(train['id_0'+str(i)], 0.05)\n",
        "    md1 = find_Major_Devices(mv1, train['id_0'+str(i)])\n",
        "    plothis1 = find_plot(md1, train, train['id_0'+str(i)])\n",
        "    plt.figure(figsize=(12,5))\n",
        "    if type(plothis1) != int:\n",
        "        p4 = sns.countplot(x = plothis1['id_0'+str(i)], hue = plothis1['isFraud'], data= plothis1)\n",
        "        plt.title(\"Data analysis of an id_\"+str(i))\n",
        "        p4.set(xlabel='id data of id_'+str(i), ylabel='Count')\n",
        "        p4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl6u7UifdusH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(10,39):\n",
        "    mv1 = find_Major_values(train['id_'+str(i)], 0.05)\n",
        "    md1 = find_Major_Devices(mv1, train['id_'+str(i)])\n",
        "    plothis1 = find_plot(md1, train, train['id_'+str(i)])\n",
        "    plt.figure(figsize=(12,5))\n",
        "    if type(plothis1) != int:\n",
        "        p4 = sns.countplot(x = plothis1['id_'+str(i)], hue = plothis1['isFraud'], data= plothis1)\n",
        "        plt.title(\"Data analysis of id_\"+str(i))\n",
        "        p4.set(xlabel='id data of id_'+str(i), ylabel='Count')\n",
        "        p4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2n2OlVHdusJ",
        "colab_type": "text"
      },
      "source": [
        "## Device type V fraud count "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UdVj4uNedusK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot(train['DeviceType'], hue='isFraud', data=train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU16thXndusM",
        "colab_type": "text"
      },
      "source": [
        "## Majorly used Devices V Fraud count "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmWajfg9dusN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv = find_Major_values(train['DeviceInfo'], 0.1)\n",
        "md = find_Major_Devices(mv, train['DeviceInfo'])\n",
        "plothis = find_plot(md, train, train['DeviceInfo'])\n",
        "\n",
        "p3 = sns.countplot(x = plothis['DeviceInfo'], hue = plothis['isFraud'], data= plothis)\n",
        "plt.title(\"Data analysis of majorly used devices\")\n",
        "p3.set(xlabel='Devices', ylabel='Count')\n",
        "p3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U4N7w0VdusP",
        "colab_type": "text"
      },
      "source": [
        ">> ## Data Processing for ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPiH5ZJqdusP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.drop(cols_to_drop, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuQlxk25dusR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.replace(np.inf,999)\n",
        "test = test.replace(np.inf,999)\n",
        "\n",
        "train['TransactionAmt'] = np.log1p(train['TransactionAmt'])\n",
        "test['TransactionAmt'] = np.log1p(test['TransactionAmt'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NhuVL2PydusS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87yRNxwAdusU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = train['isFraud']\n",
        "train = pd.get_dummies(train)\n",
        "X_train = train.drop('isFraud', axis=1)\n",
        "X_train = X_train.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4dxVmPjdusW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3TXlIz6GdusY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q = 0\n",
        "scaler = MinMaxScaler()\n",
        "for col in X_train.columns:\n",
        "    a = np.array(X_train[col])\n",
        "    a = a.reshape(-1,1)\n",
        "    X_train[col] = scaler.fit_transform(a)\n",
        "    if q >= 100:\n",
        "        break\n",
        "    else:\n",
        "        q+=1\n",
        "        continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGHd82OkdusZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLyW54JXlxsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "from sklearn.externals import joblib\n",
        "joblib.dump(x, 'dataset.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k15TYR-7om-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "joblib.dump(y_train, 'datasety.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-ptUFs_mO0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del X_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmnsqB_NmTxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = joblib.load('dataset.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZyefrX6qGPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = joblib.load('datasety.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqtM9kt2dusb",
        "colab_type": "text"
      },
      "source": [
        ">> ## Machine Learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dyL2hjd3K3D",
        "colab_type": "text"
      },
      "source": [
        "##Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CQyBURYdusb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
        "lr.fit(x_train, y_train[:np.shape(x_train)[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUTV5RfS3QW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = cross_val_score(lr, x_train, y_train[:np.shape(x_train)[0]], cv=3, verbose=3)\n",
        "score.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44WObi9c4wEL",
        "colab_type": "text"
      },
      "source": [
        "##Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uhPly-M4638",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = RandomForestClassifier(n_estimators=1000, bootstrap=False, max_features=0.33, n_jobs=4)\n",
        "rf.fit(x_train, y_train[:np.shape(x_train)[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RF1Vqa-5Gbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = cross_val_score(lr, x_train, y_train[:np.shape(x_train)[0]], cv=3, verbose=3)\n",
        "score.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}